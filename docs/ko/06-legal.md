# InfoMesh — 법적 고려사항

---

## 1. 개요

InfoMesh는 분산 크롤링 + 인덱싱 시스템으로서, 법적 리스크를 최소화하면서도  
유용한 검색 서비스를 제공하기 위한 명확한 규칙이 필요합니다.

---

## 2. robots.txt 준수

| 항목 | 정책 |
|------|------|
| 준수 여부 | **엄격 준수** — opt-out 존중 |
| User-Agent | `InfoMesh` 전용 UA 사용 |
| Crawl-delay | robots.txt에 지정된 경우 준수, 미지정 시 기본 1초/도메인 |
| 차단 경로 | `Disallow` 경로는 절대 크롤링하지 않음 |
| Sitemap | robots.txt의 Sitemap 지시어가 있으면 우선 활용 |

### 구현 원칙

- 크롤링 시작 전 반드시 `robots.txt` 확인
- 캐시 유효기간: 최대 24시간, 이후 재확인
- 해석 실패 시 **보수적으로** 동작 (크롤링하지 않음)

---

## 3. 저작권 보호

| 항목 | 정책 |
|------|------|
| 전문 저장 | **캐시 목적 한정** — 검색 인덱스 생성용 |
| 검색 결과 반환 | **스니펫만** 반환 (원문 링크 제공) |
| 캐시 삭제 | 원본 사이트 robots.txt 변경 or 요청 시 캐시 삭제 |
| LLM 요약 | 요약본은 파생 저작물이 아닌 **사실적 정보 추출**로 처리 |

### 구현 원칙

- MCP `search()` 결과: 제목 + 스니펫(~200자) + URL
- MCP `fetch_page()`: 캐시된 전문 반환 시 원본 출처 명시
- 저작권자 요청 시 삭제 대응 프로세스 필요

---

## 4. GDPR (개인정보 보호)

| 항목 | 정책 |
|------|------|
| 개인정보 크롤링 | **제외 옵션** 제공 |
| 검색 쿼리 기록 | **중앙 기록 없음** — P2P 특성상 쿼리가 중앙에 수집되지 않음 |
| 데이터 삭제 | 특정 URL/도메인 삭제 요청 시 로컬 인덱스에서 제거 |
| 사용자 데이터 | 노드 운영자의 IP 외에 개인정보 수집 없음 |

### 구현 원칙

- 크롤링 시 개인정보 감지 휴리스틱 적용 (이메일, 전화번호 등 패턴)
- 감지된 페이지 인덱싱 시 개인정보 부분 마스킹 옵션
- GDPR 관할 지역 노드는 설정에서 강화된 필터 사용 가능

---

## 5. 이용약관 (ToS) 준수

| 항목 | 정책 |
|------|------|
| 크롤링 금지 사이트 | **블랙리스트** 유지 관리 |
| 블랙리스트 업데이트 | DHT를 통한 분산 블랙리스트 동기화 |
| 사이트 요청 | 크롤링 제외 요청 시 블랙리스트에 추가 |
| 기본 블랙리스트 | 프로젝트 배포 시 알려진 금지 사이트 포함 |
| ToS 자동 감지 | robots.txt 외에 일반 ToS 패턴 휴리스틱 스캔 |

### 구현 원칙

- `infomesh/crawler/robots.py`에서 블랙리스트 확인 로직 통합
- 블랙리스트는 로컬 + DHT 동기화 이중 관리
- 커뮤니티 리포트 시스템으로 블랙리스트 업데이트
- **기본 블랙리스트**에 크롤링 금지 ToS가 있는 사이트 포함 (예: LinkedIn, Facebook, Instagram)
- **ToS 휴리스틱 감지**: 최초 도메인 크롤링 시 페이지 하단 / `/terms` / `/tos` URL을 스캔하여 "자동 접근 금지", "스크래핑 금지" 등의 키워드 감지 → 지속 크롤링 전 검토 플래그

---

## 6. LLM 요약 출처 표기

| 항목 | 정책 |
|------|------|
| 요약 출처 | 항상 `content_hash`로 요약과 원본 콘텐츠 연결 |
| 요약 라벨 | LLM 생성 요약을 "AI 생성 요약"으로 표시 |
| 원본 접근 | 요약과 함께 항상 원본 소스 URL 링크 제공 |
| 요약 검증 | 검증된 요약([신뢰 & 무결성](07-trust-integrity.md) 참조)은 검증 완료 라벨 표시 |

### 구현 원칙

- 모든 요약에 `content_hash` (SHA-256 소스 텍스트 해시) 함께 저장
- 요약을 포함한 MCP 검색 결과에는 `source_url`과 `is_ai_summary: true` 필수 포함
- 검증 실패한 요약(NLI 모순 감지)은 폐기하고 제공하지 않음

---

## 7. DMCA 게시 중단 전파

| 항목 | 정책 |
|------|------|
| 게시 중단 요청 | 노드 운영자가 DMCA 스타일 삭제 요청 제출 가능 |
| 전파 | 서명된 삭제 레코드를 DHT에 발행 → 콘텐츠 보유 노드 모두 준수 필수 |
| 검증 | 삭제 레코드는 요청자 서명 첨부; 노드는 실행 전 검증 |
| 감사 준수 | 랜덤 감사 시 삭제된 콘텐츠가 더 이상 제공되지 않는지 확인 |
| 응답 시간 | 노드는 삭제 레코드 수신 후 24시간 내 처리 필수 |

### 구현 원칙

- DMCA 레코드는 콘텐츠 레코드와 동일한 증명 체인 사용 (Ed25519 서명)
- 삭제 레코드 형식: `(url, content_hash, reason, requester_signature, timestamp)`
- 3회 감사 확인 후에도 미준수 노드는 신뢰 점수 감점
- 투명성을 위한 공개 `DMCA_LOG` 유지 (해시만, 콘텐츠 미포함)

---

## 8. `fetch_page()` 콘텐츠 제한

MCP `fetch_page()` 도구는 URL의 전문을 캐시 또는 실시간 크롤링으로 반환합니다. 신중한 제한이 필요합니다:

| 항목 | 정책 |
|------|------|
| 페이월 감지 | 로그인 벽 / 페이월 휴리스틱 감지 → 부분 콘텐츠 대신 오류 반환 |
| 캐시 TTL | 캐시 콘텐츠 7일 후 만료; 만료 후 재크롤링 또는 "오래됨" 경고 반환 |
| 원본 사이트 확인 | 원본 사이트 이용 가능 시 오래된 캐시보다 실시간 크롤링 선호 |
| 콘텐츠 크기 제한 | `fetch_page()` 호출당 최대 100KB 텍스트 반환 |
| 출처 표기 | 항상 `source_url`, `crawl_timestamp`, `is_cached: true/false` 포함 |

### 구현 원칙

- 페이월 지표: HTTP 402/403, 메타 태그 (`<meta name="robots" content="noarchive">`), 로그인 폼 감지
- 캐시로부터의 콘텐츠가 24시간 이상 경과 시 `stale_warning: true` 포함
- 차단 목록의 URL에 대해서는 `fetch_page()` 결과 제공 금지

---

## 9. GDPR 분산 삭제

P2P 네트워크에서 삭제 요청은 데이터를 보유한 모든 노드로 전파되어야 합니다:

| 항목 | 정책 |
|------|------|
| 삭제 요청 | 특정 URL/content_hash에 대한 서명된 DHT 삭제 레코드 |
| 전파 | 가십 프로토콜로 모든 복제 노드에 요청 전달 보장 |
| 검증 | 랜덤 감사가 삭제된 콘텐츠 제거 확인 (DMCA와 동일 메커니즘) |
| 범위 | 적용 대상: 로컬 인덱스, 캐시 텍스트, DHT 포인터, 요약 |
| 잊힐 권리 | URL 기반 삭제 시 요약 포함 모든 관련 데이터 제거 |

### 구현 원칙

- 재인덱싱 방지를 위해 삭제 레코드를 DHT에 영구 저장
- 이후 참여하는 노드는 동기화 시 누적된 삭제 레코드 수신
- `infomesh delete --url <URL>` CLI 명령으로 로컬 운영자 사용
- 감사 추적을 위한 삭제 요청 로그 (해시만)

---

## 10. Common Crawl 데이터 사용

| 항목 | 정책 |
|------|------|
| URL 리스트 | Common Crawl 이용약관에 따라 자유롭게 사용 가능 |
| 전체 콘텐츠 | 원본 사이트의 저작권에 종속 — 인덱싱 용도만, 재배포 불가 |
| 출처 표기 | 문서와 `network_stats()`에서 Common Crawl을 데이터 소스로 명시 |
| 필터링 | Common Crawl 임포트에도 차단 목록 및 개인정보 필터 적용 |

---

## 11. InfoMesh 프로젝트 라이선스

| 항목 | 정책 |
|------|------|
| 소스 코드 | 허용적 오픈소스 라이선스 (MIT 또는 Apache 2.0) |
| 이용약관 | 리포지토리 루트의 `TERMS_OF_USE.md` — 노드 운영자 책임 명시 |
| 기여자 동의 | 기여자는 동일 라이선스 하에 기여물을 라이선스하는 것에 동의 |
| 데이터 책임 | 각 노드 운영자는 현지법 준수에 대해 책임 |

### `TERMS_OF_USE.md`에 포함할 내용:

- 노드 운영자는 robots.txt 및 차단 목록 준수에 대한 책임
- 검색 결과의 정확성 또는 가용성에 대한 보증 없음
- 웹에서 크롤링된 콘텐츠에 대한 면책
- GDPR 관할 지역의 노드 운영자는 강화 필터링 활성화 필수
- 네트워크 남용 (시빌 공격, 크레딧 파밍) 시 네트워크 격리 가능

---

## 12. 요약

```
┌─────────────────────────────────────────────────┐
│                법적 준수 체크리스트               │
│                                                 │
│  ✓ robots.txt 엄격 준수                         │
│  ✓ 저작권: 캐시 한정, 스니펫만 반환              │
│  ✓ GDPR: 개인정보 제외, 중앙 기록 없음           │
│  ✓ GDPR: 분산 삭제 전파                         │
│  ✓ ToS: 블랙리스트 + 자동 감지 휴리스틱          │
│  ✓ 크롤링 속도: 도메인당 ≤1 요청/초              │
│  ✓ 출처 표기: 항상 원문 URL 제공                 │
│  ✓ LLM 요약: 라벨 표시 + 검증 + 출처 명시        │
│  ✓ DMCA: 서명된 게시 중단 DHT 전파               │
│  ✓ fetch_page(): 페이월 감지 + 캐시 TTL          │
│  ✓ Common Crawl: 적절한 출처 표기 + 필터링       │
│  ✓ 프로젝트: TERMS_OF_USE.md + 오픈소스 라이선스 │
└─────────────────────────────────────────────────┘
```

---

*관련 문서: [개요](01-overview.md) · [아키텍처](02-architecture.md) · [크레딧 시스템](03-credit-system.md) · [기술 스택](04-tech-stack.md) · [신뢰 & 무결성](07-trust-integrity.md) · [보안 감사](08-security-audit.md) · [콘솔 대시보드](09-console-dashboard.md) · [MCP 연동](10-mcp-integration.md) · [배포](11-publishing.md)*
